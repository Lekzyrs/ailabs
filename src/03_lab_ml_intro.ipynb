{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc9520d2",
   "metadata": {},
   "source": [
    "# Лабораторная работа №3\n",
    "\n",
    "ФИО:   \n",
    "Группа: \n",
    "\n",
    "Отправлять можно следующими способами:\n",
    "1. Запушить этот ноутбук в GitHub в репозиторий, где у вас лежат ноутбуки с лабами\n",
    "\n",
    "Deadlines:\n",
    "- Занятие №6 в семестре\n",
    "\n",
    "Что необходимо сделать:  \n",
    "- Обучить различного рода модели машинного обучения и сравнить их между собой  \n",
    "\n",
    "---\n",
    "## Читайте задание внимательно\n",
    "\n",
    "Исходные данные:\n",
    "1. В [табличке](https://docs.google.com/spreadsheets/d/1NOE0D4JQgD6LbvUqWboUI1TFj4P87ugbqUTDquxlGEI/edit?usp=sharing) необходимо узнать название своего датасета \n",
    "2. Скачать нужны вам данные можно в [Google Drive](https://drive.google.com/drive/folders/1sbsjBsJ_ln0XgXCI9R6s17pvyvApgcwF?usp=sharing)\n",
    "  \n",
    "---\n",
    "Теперь по пунктам, что я от вас жду:  \n",
    "1. Загрузить необходимые данные к себе и считать (read) их в переменную.\n",
    "2. Понять, у вас задача классификации (бинарной или многоклассовой) или регрессии (**если у вас многоклассовая классификация, прочтите P.S.S. внизу**).\n",
    "3. Сделать предобработку данных:  \n",
    "     1. Разделить выборку на тренировочную (train) и тестовую (test). _Обратите внимание, что обучать скейлеры и определять, какими значениями вы будете заполнять пропуски, вы будете на train выборке, а применять и на train, и на test_.\n",
    "     2. Проверить пропуски в данных. Если они есть, заполнить одной из стратегий, предложенных в ноутбуке для семинара №3. P.S. Для численных и категориальных переменных будут разные стратегии.\n",
    "     3. Отнормировать численные переменные (`StandardScaler`, `MinMaxScaler`).\n",
    "     4. Закодировать категориальные признаки по одной из стратегий.\n",
    "4. Обучить на тренировочном множестве:\n",
    "     1. Линейную модель (`LogisticRegression`, `LinearRegression`)\n",
    "     2. Деревянную модель (`DecisionTreeClassifier`, `DecisionTreeRegressor`) (тут советую попробовать разные глубины деревьев)\n",
    "     3. K-ближайших соседей (`KNeighborsClassifier`, `KNeighborsRegressor`) (тут тоже есть смысл попробовать разные `k`)\n",
    "     4. Случайный лес (`RandomForestClassifier`, `RandomForestRegressor`) \n",
    "5. Посчитайте метрики на train и test множествах:\n",
    "     1. Для задачи классификации -- Accuracy, ROC-AUC (график + значение), PR-кривую (график), F1-score\n",
    "     2. Для задачи регрессии -- MAE, RMSE, MAPE\n",
    "6. Сравните метрики относительно train/test, так и относительно разных моделей. Ответьте на следующие вопросы:\n",
    "     1. Какая модель справилась лучше с поставленной задачей?\n",
    "     2. Имеет ли место переобучение?\n",
    "     3. Имеет ли место недообучение?\n",
    "     4. Как можно улучшить метрики моделей?\n",
    "\n",
    "---\n",
    "P.S.  \n",
    "Просьба -- делать каждое задание в отдельных ячейках и с отдельными заголовками (как пункт 1 и 2 в этом ноутбуке) типа  \n",
    "- Заголовок\n",
    "- Ячейки с кодом\n",
    "- Другой заголовок\n",
    "- Другие ячейки с кодом\n",
    "\n",
    "P.S.S.  \n",
    "Если вам повезло с многоклассовой классификацией, вам будет необходимо понять, умеет ли алгоритм работать с несколькими классами одновременно (обычно они не умеют). Поэтому вам может понадобиться такая штука, как OneVsRestClassifier ([ссылка](https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html#sklearn.multiclass.OneVsRestClassifier)), но советую ознакомиться с этой [страницей](https://scikit-learn.org/stable/modules/multiclass.html), здесь представлена более полная информация."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b51062",
   "metadata": {},
   "source": [
    "## 1. Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "406597a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер датасета: (952, 24)\n",
      "\n",
      "Первые 5 строк:\n",
      "                            track_name    artist(s)_name  artist_count  \\\n",
      "0  Seven (feat. Latto) (Explicit Ver.)  Latto, Jung Kook             2   \n",
      "1                                 LALA       Myke Towers             1   \n",
      "2                              vampire    Olivia Rodrigo             1   \n",
      "3                         Cruel Summer      Taylor Swift             1   \n",
      "4                       WHERE SHE GOES         Bad Bunny             1   \n",
      "\n",
      "   released_year  released_month  released_day  in_spotify_playlists  \\\n",
      "0           2023               7            14                   553   \n",
      "1           2023               3            23                  1474   \n",
      "2           2023               6            30                  1397   \n",
      "3           2019               8            23                  7858   \n",
      "4           2023               5            18                  3133   \n",
      "\n",
      "   in_spotify_charts    streams  in_apple_playlists  ...  bpm key   mode  \\\n",
      "0                147  141381703                  43  ...  125   B  Major   \n",
      "1                 48  133716286                  48  ...   92  C#  Major   \n",
      "2                113  140003974                  94  ...  138   F  Major   \n",
      "3                100  800840817                 116  ...  170   A  Major   \n",
      "4                 50  303236322                  84  ...  144   A  Minor   \n",
      "\n",
      "  danceability_%  valence_% energy_% acousticness_%  instrumentalness_%  \\\n",
      "0             80         89       83             31                   0   \n",
      "1             71         61       74              7                   0   \n",
      "2             51         32       53             17                   0   \n",
      "3             55         58       72             11                   0   \n",
      "4             65         23       80             14                  63   \n",
      "\n",
      "   liveness_%  speechiness_%  \n",
      "0           8              4  \n",
      "1          10              4  \n",
      "2          31              6  \n",
      "3          11             15  \n",
      "4          11              6  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "\n",
      "Информация о датасете:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 952 entries, 0 to 951\n",
      "Data columns (total 24 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   track_name            952 non-null    object\n",
      " 1   artist(s)_name        952 non-null    object\n",
      " 2   artist_count          952 non-null    int64 \n",
      " 3   released_year         952 non-null    int64 \n",
      " 4   released_month        952 non-null    int64 \n",
      " 5   released_day          952 non-null    int64 \n",
      " 6   in_spotify_playlists  952 non-null    int64 \n",
      " 7   in_spotify_charts     952 non-null    int64 \n",
      " 8   streams               952 non-null    int64 \n",
      " 9   in_apple_playlists    952 non-null    int64 \n",
      " 10  in_apple_charts       952 non-null    int64 \n",
      " 11  in_deezer_playlists   952 non-null    object\n",
      " 12  in_deezer_charts      952 non-null    int64 \n",
      " 13  in_shazam_charts      902 non-null    object\n",
      " 14  bpm                   952 non-null    int64 \n",
      " 15  key                   857 non-null    object\n",
      " 16  mode                  952 non-null    object\n",
      " 17  danceability_%        952 non-null    int64 \n",
      " 18  valence_%             952 non-null    int64 \n",
      " 19  energy_%              952 non-null    int64 \n",
      " 20  acousticness_%        952 non-null    int64 \n",
      " 21  instrumentalness_%    952 non-null    int64 \n",
      " 22  liveness_%            952 non-null    int64 \n",
      " 23  speechiness_%         952 non-null    int64 \n",
      "dtypes: int64(18), object(6)\n",
      "memory usage: 178.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv('/Users/lekzyrs/Desktop/ailabs/data/spotify-2023.csv', sep=',', encoding='latin-1')\n",
    "\n",
    "# Выводим информацию о загруженных данных\n",
    "print(f\"Размер датасета: {data.shape}\")\n",
    "print(f\"\\nПервые 5 строк:\")\n",
    "print(data.head())\n",
    "print(f\"\\nИнформация о датасете:\")\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d119028",
   "metadata": {},
   "source": [
    "## 2. Понимаем, какая перед нами задача"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d92464d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Тип задачи: РЕГРЕССИЯ\n"
     ]
    }
   ],
   "source": [
    "# Определяем целевую переменную\n",
    "target_variable = 'streams'\n",
    "\n",
    "# Преобразуем streams в числовой формат (на случай, если есть строки с запятыми)\n",
    "if target_variable in data.columns:\n",
    "    data[target_variable] = data[target_variable].astype(str).str.replace(',', '').astype(float)\n",
    "\n",
    "# Определяем тип задачи\n",
    "unique_values = data[target_variable].nunique()\n",
    "is_continuous = data[target_variable].dtype in ['float64', 'int64', 'float32', 'int32']\n",
    "\n",
    "if is_continuous and unique_values > 20:\n",
    "    task_type = \"РЕГРЕССИЯ\"\n",
    "elif unique_values == 2:\n",
    "    task_type = \"БИНАРНАЯ КЛАССИФИКАЦИЯ\"\n",
    "else:\n",
    "    task_type = \"МНОГОКЛАССОВАЯ КЛАССИФИКАЦИЯ\"\n",
    "\n",
    "print(f\"Тип задачи: {task_type}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34931f43",
   "metadata": {},
   "source": [
    "## 3. Делаем предобработку данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67a611d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер признаков: (952, 21)\n",
      "Размер целевой переменной: (952,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Определяем целевую переменную\n",
    "target_variable = 'streams'\n",
    "\n",
    "# Преобразуем streams в числовой формат (если еще не сделано)\n",
    "if target_variable in data.columns:\n",
    "    if data[target_variable].dtype == 'object':\n",
    "        data[target_variable] = data[target_variable].astype(str).str.replace(',', '').astype(float)\n",
    "\n",
    "# Разделяем на признаки и целевую переменную\n",
    "X = data.drop(columns=[target_variable])\n",
    "y = data[target_variable]\n",
    "\n",
    "# Удаляем неинформативные колонки (названия треков и исполнителей)\n",
    "X = X.drop(columns=['track_name', 'artist(s)_name'], errors='ignore')\n",
    "\n",
    "# Преобразуем численные колонки, которые могут быть строками с запятыми\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == 'object':\n",
    "        # Пытаемся преобразовать в число (убираем запятые)\n",
    "        try:\n",
    "            X[col] = X[col].astype(str).str.replace(',', '').astype(float)\n",
    "        except:\n",
    "            pass  # Оставляем как есть, если не получается преобразовать\n",
    "\n",
    "print(f\"Размер признаков: {X.shape}\")\n",
    "print(f\"Размер целевой переменной: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a67a85a",
   "metadata": {},
   "source": [
    "### 3.1. Разделение на train и test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34d8be7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер train выборки: (761, 21)\n",
      "Размер test выборки: (191, 21)\n"
     ]
    }
   ],
   "source": [
    "# Разделение на train и test (80/20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Размер train выборки: {X_train.shape}\")\n",
    "print(f\"Размер test выборки: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e65152",
   "metadata": {},
   "source": [
    "### 3.2. Проверка и заполнение пропусков\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27f74d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пропуски в train выборке:\n",
      "in_shazam_charts    42\n",
      "key                 80\n",
      "dtype: int64\n",
      "\n",
      "Численные признаки: 19\n",
      "Категориальные признаки: 2\n",
      "\n",
      "Пропуски после заполнения:\n",
      "Train: 0\n",
      "Test: 0\n"
     ]
    }
   ],
   "source": [
    "# Проверяем пропуски в train выборке\n",
    "print(\"Пропуски в train выборке:\")\n",
    "print(X_train.isnull().sum()[X_train.isnull().sum() > 0])\n",
    "\n",
    "# Разделяем на численные и категориальные признаки\n",
    "numeric_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_cols = X_train.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"\\nЧисленные признаки: {len(numeric_cols)}\")\n",
    "print(f\"Категориальные признаки: {len(categorical_cols)}\")\n",
    "\n",
    "# Обучаем импьютеры на train выборке\n",
    "# Для численных признаков - медиана\n",
    "numeric_imputer = SimpleImputer(strategy='median')\n",
    "X_train[numeric_cols] = numeric_imputer.fit_transform(X_train[numeric_cols])\n",
    "\n",
    "# Для категориальных признаков - наиболее частое значение\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "if categorical_cols:\n",
    "    X_train[categorical_cols] = categorical_imputer.fit_transform(X_train[categorical_cols])\n",
    "\n",
    "# Применяем импьютеры к test выборке\n",
    "X_test[numeric_cols] = numeric_imputer.transform(X_test[numeric_cols])\n",
    "if categorical_cols:\n",
    "    X_test[categorical_cols] = categorical_imputer.transform(X_test[categorical_cols])\n",
    "\n",
    "print(\"\\nПропуски после заполнения:\")\n",
    "print(f\"Train: {X_train.isnull().sum().sum()}\")\n",
    "print(f\"Test: {X_test.isnull().sum().sum()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1742a1",
   "metadata": {},
   "source": [
    "### 3.3. Нормализация численных переменных\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc1dc8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Численные признаки нормализованы с помощью StandardScaler\n",
      "Пример нормализованных данных (первые 3 строки, первые 3 признака):\n",
      "     artist_count  released_year  released_month\n",
      "318     -0.611873       0.332593        1.113503\n",
      "545     -0.611873      -0.027696       -0.866347\n",
      "557     -0.611873       0.332593       -1.432018\n"
     ]
    }
   ],
   "source": [
    "# Используем StandardScaler для нормализации численных признаков\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Обучаем на train и применяем к train и test\n",
    "X_train[numeric_cols] = scaler.fit_transform(X_train[numeric_cols])\n",
    "X_test[numeric_cols] = scaler.transform(X_test[numeric_cols])\n",
    "\n",
    "print(\"Численные признаки нормализованы с помощью StandardScaler\")\n",
    "print(f\"Пример нормализованных данных (первые 3 строки, первые 3 признака):\")\n",
    "print(X_train[numeric_cols[:3]].head(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf268720",
   "metadata": {},
   "source": [
    "### 3.4. Кодирование категориальных признаков\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "babf04d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Категориальные признаки закодированы с помощью OneHotEncoder\n",
      "Количество новых признаков после кодирования: 11\n",
      "\n",
      "Финальный размер train: (761, 30)\n",
      "Финальный размер test: (191, 30)\n",
      "\n",
      "Первые 5 признаков:\n",
      "   artist_count  released_year  released_month  released_day  \\\n",
      "0     -0.611873       0.332593        1.113503      1.322189   \n",
      "1     -0.611873      -0.027696       -0.866347     -0.528218   \n",
      "2     -0.611873       0.332593       -1.432018     -0.528218   \n",
      "3     -0.611873      -0.658202       -1.432018     -1.398997   \n",
      "4      0.494150       0.332593        0.830667      0.886799   \n",
      "\n",
      "   in_spotify_playlists  in_spotify_charts  in_apple_playlists  \\\n",
      "0             -0.593057          -0.517854           -0.510071   \n",
      "1             -0.169046          -0.029881           -0.397661   \n",
      "2             -0.407140          -0.615448           -0.307732   \n",
      "3              1.174838           1.482833            0.220596   \n",
      "4              0.407385           1.434036            1.659447   \n",
      "\n",
      "   in_apple_charts  in_deezer_playlists  in_deezer_charts  ...  key_B  key_C#  \\\n",
      "0        -0.965242            -0.323743         -0.441310  ...    0.0     0.0   \n",
      "1         0.972678            -0.260976         -0.441310  ...    0.0     0.0   \n",
      "2         1.360262             0.001423         -0.441310  ...    0.0     0.0   \n",
      "3         1.166470             1.543563          0.350385  ...    0.0     0.0   \n",
      "4         1.088953            -0.053498          3.675503  ...    0.0     0.0   \n",
      "\n",
      "   key_D  key_D#  key_E  key_F  key_F#  key_G  key_G#  mode_Minor  \n",
      "0    0.0     0.0    0.0    0.0     0.0    0.0     1.0         1.0  \n",
      "1    1.0     0.0    0.0    0.0     0.0    0.0     0.0         0.0  \n",
      "2    1.0     0.0    0.0    0.0     0.0    0.0     0.0         1.0  \n",
      "3    1.0     0.0    0.0    0.0     0.0    0.0     0.0         1.0  \n",
      "4    1.0     0.0    0.0    0.0     0.0    0.0     0.0         0.0  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Используем OneHotEncoder для категориальных признаков\n",
    "if categorical_cols:\n",
    "    ohe = OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore')\n",
    "    \n",
    "    # Обучаем на train и применяем к train и test\n",
    "    X_train_encoded = ohe.fit_transform(X_train[categorical_cols])\n",
    "    X_test_encoded = ohe.transform(X_test[categorical_cols])\n",
    "    \n",
    "    # Создаем DataFrame с закодированными признаками\n",
    "    feature_names = ohe.get_feature_names_out(categorical_cols)\n",
    "    X_train_encoded_df = pd.DataFrame(X_train_encoded, columns=feature_names, index=X_train.index)\n",
    "    X_test_encoded_df = pd.DataFrame(X_test_encoded, columns=feature_names, index=X_test.index)\n",
    "    \n",
    "    # Объединяем численные и закодированные категориальные признаки\n",
    "    X_train_final = pd.concat([X_train[numeric_cols].reset_index(drop=True), \n",
    "                               X_train_encoded_df.reset_index(drop=True)], axis=1)\n",
    "    X_test_final = pd.concat([X_test[numeric_cols].reset_index(drop=True), \n",
    "                              X_test_encoded_df.reset_index(drop=True)], axis=1)\n",
    "    \n",
    "    print(f\"Категориальные признаки закодированы с помощью OneHotEncoder\")\n",
    "    print(f\"Количество новых признаков после кодирования: {len(feature_names)}\")\n",
    "else:\n",
    "    X_train_final = X_train[numeric_cols].reset_index(drop=True)\n",
    "    X_test_final = X_test[numeric_cols].reset_index(drop=True)\n",
    "    print(\"Категориальных признаков нет\")\n",
    "\n",
    "print(f\"\\nФинальный размер train: {X_train_final.shape}\")\n",
    "print(f\"Финальный размер test: {X_test_final.shape}\")\n",
    "print(f\"\\nПервые 5 признаков:\")\n",
    "print(X_train_final.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec493bb1",
   "metadata": {},
   "source": [
    "## 4. Обучение моделей\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724aeed0",
   "metadata": {},
   "source": [
    "### 4.1. Линейная модель (LinearRegression)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "786cca66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Линейная модель обучена\n",
      "Коэффициенты модели: 30 признаков\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Обучаем линейную модель\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_final, y_train)\n",
    "\n",
    "print(\"Линейная модель обучена\")\n",
    "print(f\"Коэффициенты модели: {len(lr_model.coef_)} признаков\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c44190",
   "metadata": {},
   "source": [
    "### 4.2. Деревянная модель (DecisionTreeRegressor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d70208f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Дерево с глубиной 3 обучено\n",
      "Дерево с глубиной 5 обучено\n",
      "Дерево с глубиной 10 обучено\n",
      "Дерево с глубиной 15 обучено\n",
      "Дерево с глубиной 20 обучено\n",
      "Дерево с глубиной None обучено\n",
      "\n",
      "Всего обучено 6 деревьев с разными глубинами\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Обучаем деревья с разными глубинами\n",
    "tree_models = {}\n",
    "depths = [3, 5, 10, 15, 20, None]\n",
    "\n",
    "for depth in depths:\n",
    "    tree_model = DecisionTreeRegressor(max_depth=depth, random_state=42)\n",
    "    tree_model.fit(X_train_final, y_train)\n",
    "    tree_models[f'depth_{depth}'] = tree_model\n",
    "    print(f\"Дерево с глубиной {depth} обучено\")\n",
    "\n",
    "print(f\"\\nВсего обучено {len(tree_models)} деревьев с разными глубинами\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed84019",
   "metadata": {},
   "source": [
    "### 4.3. K-ближайших соседей (KNeighborsRegressor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52272399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN с k=3 обучен\n",
      "KNN с k=5 обучен\n",
      "KNN с k=7 обучен\n",
      "KNN с k=10 обучен\n",
      "KNN с k=15 обучен\n",
      "KNN с k=20 обучен\n",
      "\n",
      "Всего обучено 6 моделей KNN с разными k\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Обучаем KNN с разными значениями k\n",
    "knn_models = {}\n",
    "k_values = [3, 5, 7, 10, 15, 20]\n",
    "\n",
    "for k in k_values:\n",
    "    knn_model = KNeighborsRegressor(n_neighbors=k)\n",
    "    knn_model.fit(X_train_final, y_train)\n",
    "    knn_models[f'k_{k}'] = knn_model\n",
    "    print(f\"KNN с k={k} обучен\")\n",
    "\n",
    "print(f\"\\nВсего обучено {len(knn_models)} моделей KNN с разными k\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5ce20a",
   "metadata": {},
   "source": [
    "### 4.4. Случайный лес (RandomForestRegressor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bac43b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Случайный лес обучен\n",
      "Количество деревьев: 100\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Обучаем случайный лес\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train_final, y_train)\n",
    "\n",
    "print(\"Случайный лес обучен\")\n",
    "print(f\"Количество деревьев: {rf_model.n_estimators}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030651ea",
   "metadata": {},
   "source": [
    "## 5. Расчет метрик на train и test множествах\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfe0af94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Функции для расчета метрик готовы\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import math\n",
    "\n",
    "# Функции для расчета метрик регрессии\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\"Рассчитывает MAE, RMSE и MAPE\"\"\"\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = math.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    # MAPE - избегаем деления на ноль\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / (y_true + 1e-10))) * 100\n",
    "    return mae, rmse, mape\n",
    "\n",
    "# Убеждаемся, что y_train и y_test имеют правильный формат\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "print(\"Функции для расчета метрик готовы\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce02ded",
   "metadata": {},
   "source": [
    "### 5.1. Метрики для LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37cbd873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрики для LinearRegression:\n",
      "Train - MAE: 188233390.40, RMSE: 283537751.09, MAPE: 15070.07%\n",
      "Test  - MAE: 188047096.02, RMSE: 267344393.42, MAPE: 87.52%\n"
     ]
    }
   ],
   "source": [
    "# Предсказания для LinearRegression\n",
    "lr_train_pred = lr_model.predict(X_train_final)\n",
    "lr_test_pred = lr_model.predict(X_test_final)\n",
    "\n",
    "# Расчет метрик\n",
    "lr_train_mae, lr_train_rmse, lr_train_mape = calculate_metrics(y_train, lr_train_pred)\n",
    "lr_test_mae, lr_test_rmse, lr_test_mape = calculate_metrics(y_test, lr_test_pred)\n",
    "\n",
    "print(\"Метрики для LinearRegression:\")\n",
    "print(f\"Train - MAE: {lr_train_mae:.2f}, RMSE: {lr_train_rmse:.2f}, MAPE: {lr_train_mape:.2f}%\")\n",
    "print(f\"Test  - MAE: {lr_test_mae:.2f}, RMSE: {lr_test_rmse:.2f}, MAPE: {lr_test_mape:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae38303",
   "metadata": {},
   "source": [
    "### 5.2. Метрики для DecisionTreeRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97141085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрики для DecisionTreeRegressor:\n",
      "     Model    Train_MAE   Train_RMSE  Train_MAPE     Test_MAE    Test_RMSE  Test_MAPE\n",
      "   depth_3 1.745528e+08 2.621711e+08 8378.056733 1.859178e+08 2.848736e+08  71.979945\n",
      "   depth_5 1.296359e+08 1.888005e+08 8065.481355 1.658488e+08 2.552484e+08  60.237180\n",
      "  depth_10 2.370750e+07 4.558421e+07   19.570319 1.670805e+08 2.488139e+08  51.237488\n",
      "  depth_15 1.439779e+06 6.085118e+06    1.154526 1.661251e+08 2.496077e+08  51.906223\n",
      "  depth_20 4.883778e+03 4.834459e+04    0.006434 1.753422e+08 2.594581e+08  53.376632\n",
      "depth_None 0.000000e+00 0.000000e+00    0.000000 1.731944e+08 2.637060e+08  51.203564\n"
     ]
    }
   ],
   "source": [
    "# Расчет метрик для всех деревьев\n",
    "tree_results = []\n",
    "\n",
    "for name, model in tree_models.items():\n",
    "    train_pred = model.predict(X_train_final)\n",
    "    test_pred = model.predict(X_test_final)\n",
    "    \n",
    "    train_mae, train_rmse, train_mape = calculate_metrics(y_train, train_pred)\n",
    "    test_mae, test_rmse, test_mape = calculate_metrics(y_test, test_pred)\n",
    "    \n",
    "    tree_results.append({\n",
    "        'Model': name,\n",
    "        'Train_MAE': train_mae,\n",
    "        'Train_RMSE': train_rmse,\n",
    "        'Train_MAPE': train_mape,\n",
    "        'Test_MAE': test_mae,\n",
    "        'Test_RMSE': test_rmse,\n",
    "        'Test_MAPE': test_mape\n",
    "    })\n",
    "\n",
    "tree_results_df = pd.DataFrame(tree_results)\n",
    "print(\"Метрики для DecisionTreeRegressor:\")\n",
    "print(tree_results_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e493fccc",
   "metadata": {},
   "source": [
    "### 5.3. Метрики для KNeighborsRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0677cddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрики для KNeighborsRegressor:\n",
      "Model    Train_MAE   Train_RMSE   Train_MAPE     Test_MAE    Test_RMSE  Test_MAPE\n",
      "  k_3 1.652955e+08 2.455920e+08 10463.864175 2.242793e+08 3.212464e+08  88.894730\n",
      "  k_5 1.865328e+08 2.785481e+08 13499.708228 2.204267e+08 3.133584e+08  86.813375\n",
      "  k_7 1.956753e+08 2.934665e+08 15105.512020 2.114437e+08 3.029264e+08  87.533878\n",
      " k_10 2.053135e+08 3.095966e+08 11622.257911 2.126457e+08 3.025959e+08  91.581115\n",
      " k_15 2.144986e+08 3.239721e+08 15050.204381 2.156880e+08 3.086058e+08  97.086641\n",
      " k_20 2.215010e+08 3.368235e+08 17624.739003 2.247991e+08 3.195248e+08 100.051697\n"
     ]
    }
   ],
   "source": [
    "# Расчет метрик для всех KNN моделей\n",
    "knn_results = []\n",
    "\n",
    "for name, model in knn_models.items():\n",
    "    train_pred = model.predict(X_train_final)\n",
    "    test_pred = model.predict(X_test_final)\n",
    "    \n",
    "    train_mae, train_rmse, train_mape = calculate_metrics(y_train, train_pred)\n",
    "    test_mae, test_rmse, test_mape = calculate_metrics(y_test, test_pred)\n",
    "    \n",
    "    knn_results.append({\n",
    "        'Model': name,\n",
    "        'Train_MAE': train_mae,\n",
    "        'Train_RMSE': train_rmse,\n",
    "        'Train_MAPE': train_mape,\n",
    "        'Test_MAE': test_mae,\n",
    "        'Test_RMSE': test_rmse,\n",
    "        'Test_MAPE': test_mape\n",
    "    })\n",
    "\n",
    "knn_results_df = pd.DataFrame(knn_results)\n",
    "print(\"Метрики для KNeighborsRegressor:\")\n",
    "print(knn_results_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fa0b41",
   "metadata": {},
   "source": [
    "### 5.4. Метрики для RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a472bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрики для RandomForestRegressor:\n",
      "Train - MAE: 53765728.56, RMSE: 88086213.82, MAPE: 6047.56%\n",
      "Test  - MAE: 132754867.59, RMSE: 207724728.93, MAPE: 49.19%\n"
     ]
    }
   ],
   "source": [
    "# Предсказания для RandomForestRegressor\n",
    "rf_train_pred = rf_model.predict(X_train_final)\n",
    "rf_test_pred = rf_model.predict(X_test_final)\n",
    "\n",
    "# Расчет метрик\n",
    "rf_train_mae, rf_train_rmse, rf_train_mape = calculate_metrics(y_train, rf_train_pred)\n",
    "rf_test_mae, rf_test_rmse, rf_test_mape = calculate_metrics(y_test, rf_test_pred)\n",
    "\n",
    "print(\"Метрики для RandomForestRegressor:\")\n",
    "print(f\"Train - MAE: {rf_train_mae:.2f}, RMSE: {rf_train_rmse:.2f}, MAPE: {rf_train_mape:.2f}%\")\n",
    "print(f\"Test  - MAE: {rf_test_mae:.2f}, RMSE: {rf_test_rmse:.2f}, MAPE: {rf_test_mape:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79711fa8",
   "metadata": {},
   "source": [
    "### 5.5. Сводная таблица всех метрик\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7da9296c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "СВОДНАЯ ТАБЛИЦА МЕТРИК\n",
      "====================================================================================================\n",
      "                        Model    Train_MAE   Train_RMSE   Train_MAPE     Test_MAE    Test_RMSE  Test_MAPE\n",
      "             LinearRegression 1.882334e+08 2.835378e+08 15070.065914 1.880471e+08 2.673444e+08  87.519363\n",
      "DecisionTree (best: depth_10) 2.370750e+07 4.558421e+07    19.570319 1.670805e+08 2.488139e+08  51.237488\n",
      "             KNN (best: k_10) 2.053135e+08 3.095966e+08 11622.257911 2.126457e+08 3.025959e+08  91.581115\n",
      "        RandomForestRegressor 5.376573e+07 8.808621e+07  6047.561545 1.327549e+08 2.077247e+08  49.193517\n"
     ]
    }
   ],
   "source": [
    "# Создаем сводную таблицу всех метрик\n",
    "summary_results = []\n",
    "\n",
    "# LinearRegression\n",
    "summary_results.append({\n",
    "    'Model': 'LinearRegression',\n",
    "    'Train_MAE': lr_train_mae,\n",
    "    'Train_RMSE': lr_train_rmse,\n",
    "    'Train_MAPE': lr_train_mape,\n",
    "    'Test_MAE': lr_test_mae,\n",
    "    'Test_RMSE': lr_test_rmse,\n",
    "    'Test_MAPE': lr_test_mape\n",
    "})\n",
    "\n",
    "# Лучшее дерево (по Test_RMSE)\n",
    "best_tree = tree_results_df.loc[tree_results_df['Test_RMSE'].idxmin()]\n",
    "summary_results.append({\n",
    "    'Model': f\"DecisionTree (best: {best_tree['Model']})\",\n",
    "    'Train_MAE': best_tree['Train_MAE'],\n",
    "    'Train_RMSE': best_tree['Train_RMSE'],\n",
    "    'Train_MAPE': best_tree['Train_MAPE'],\n",
    "    'Test_MAE': best_tree['Test_MAE'],\n",
    "    'Test_RMSE': best_tree['Test_RMSE'],\n",
    "    'Test_MAPE': best_tree['Test_MAPE']\n",
    "})\n",
    "\n",
    "# Лучший KNN (по Test_RMSE)\n",
    "best_knn = knn_results_df.loc[knn_results_df['Test_RMSE'].idxmin()]\n",
    "summary_results.append({\n",
    "    'Model': f\"KNN (best: {best_knn['Model']})\",\n",
    "    'Train_MAE': best_knn['Train_MAE'],\n",
    "    'Train_RMSE': best_knn['Train_RMSE'],\n",
    "    'Train_MAPE': best_knn['Train_MAPE'],\n",
    "    'Test_MAE': best_knn['Test_MAE'],\n",
    "    'Test_RMSE': best_knn['Test_RMSE'],\n",
    "    'Test_MAPE': best_knn['Test_MAPE']\n",
    "})\n",
    "\n",
    "# RandomForestRegressor\n",
    "summary_results.append({\n",
    "    'Model': 'RandomForestRegressor',\n",
    "    'Train_MAE': rf_train_mae,\n",
    "    'Train_RMSE': rf_train_rmse,\n",
    "    'Train_MAPE': rf_train_mape,\n",
    "    'Test_MAE': rf_test_mae,\n",
    "    'Test_RMSE': rf_test_rmse,\n",
    "    'Test_MAPE': rf_test_mape\n",
    "})\n",
    "\n",
    "summary_df = pd.DataFrame(summary_results)\n",
    "print(\"=\" * 100)\n",
    "print(\"СВОДНАЯ ТАБЛИЦА МЕТРИК\")\n",
    "print(\"=\" * 100)\n",
    "print(summary_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88180c3d",
   "metadata": {},
   "source": [
    "### 6. Сравнение метрик\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7a08cc",
   "metadata": {},
   "source": [
    "\n",
    "1. **Какая модель справилась лучше:**\n",
    "\n",
    "   Лучшей моделью является RandomForestRegressor, поскольку она имеет наименьшие значения метрик на тестовой выборке:\n",
    "\n",
    "   Test MAE: 1.33e+08\n",
    "   Test RMSE: 2.08e+08\n",
    "   Test MAPE: 49.19%\n",
    "\n",
    "2. **Имеет ли место переобучение?:**\n",
    "\n",
    "   Да, переобучение имеет место у некоторых моделей:\n",
    "\n",
    "   DecisionTreeRegressor: На обучении ошибка очень низкая (MAE = 2.37e+07), но на тесте она резко возрастает (MAE = 1.67e+08), что говорит о сильном переобучении.\n",
    "\n",
    "   RandomForestRegressor также показывает заметную разницу между Train и Test, но менее выраженную, что указывает на умеренное переобучение.\n",
    "\n",
    "3. **Имеет ли место недообучение?:**\n",
    "\n",
    "   Да, недообучение имеет место у:\n",
    "\n",
    "   LinearRegression: Ошибки на обучении и тесте практически одинаковые, но при этом очень высокие (MAPE > 87%), что говорит о недообучении.\n",
    "\n",
    "   KNN: Аналогично, ошибки высокие на обеих выборках, что указывает на недостаточную обучаемость модели при текущей конфигурации\n",
    "\n",
    "4. **Как можно улучшить метрики моделей?:**\n",
    "\n",
    "   Feature Engineering: Добавить больше информативных признаков, попробовать полиномиальные признаки, логарифмирование целевой переменной и т.д.\n",
    "\n",
    "   Подбор гиперпараметров:\n",
    "   Для RandomForest: регулировать n_estimators, max_depth, min_samples_split.\n",
    "   Для DecisionTree: ограничить глубину дерева, использовать min_samples_split, min_samples_leaf.\n",
    "\n",
    "   Масштабирование признаков: Особенно важно для KNN.\n",
    "\n",
    "   Кросс-валидация: Для уверенности в правильных параметрах и снижения риска переобучения.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
